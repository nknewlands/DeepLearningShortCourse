{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Fruits_part2.ipynb","version":"0.3.2","provenance":[{"file_id":"1tpFgVdEEDRYDhV2q2MxETvHcQDpHWHXo","timestamp":1565851246517}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0A9li0oOGKF8","colab_type":"code","outputId":"9ddf736e-ed6d-4334-b5b2-5615f9c72f55","executionInfo":{"status":"ok","timestamp":1565617928220,"user_tz":240,"elapsed":8594,"user":{"displayName":"Etienne Lord","photoUrl":"https://lh4.googleusercontent.com/-5aPJcqV56uo/AAAAAAAAAAI/AAAAAAAABZE/kxLls5iyY-M/s64/photo.jpg","userId":"18414272008349868197"}},"colab":{"base_uri":"https://localhost:8080/","height":908}},"source":["###############################################################################\n","# SETUP - EXECUTE THIS FIRST                                                  #\n","###############################################################################\n","# 1. Go into \"Runtime\" -> \"Change runtime type\" and Select \"GPU\" for hardward accelerator\n","# 2. Click the \"Connect\" button, at the right to start the instance.\n","# This will get the dataset into this instance\n","!wget https://github.com/nknewlands/DeepLearningShortCourse/raw/master/Day1/Pineapple_and_Orange/new_fruits.zip\n","!unzip new_fruits.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-08-12 13:52:00--  https://github.com/nknewlands/DeepLearningShortCourse/raw/master/Day1/Pineapple_and_Orange/new_fruits.zip\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/nknewlands/DeepLearningShortCourse/master/Day1/Pineapple_and_Orange/new_fruits.zip [following]\n","--2019-08-12 13:52:05--  https://raw.githubusercontent.com/nknewlands/DeepLearningShortCourse/master/Day1/Pineapple_and_Orange/new_fruits.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12125632 (12M) [application/zip]\n","Saving to: ‘new_fruits.zip’\n","\n","new_fruits.zip      100%[===================>]  11.56M  --.-KB/s    in 0.09s   \n","\n","2019-08-12 13:52:06 (126 MB/s) - ‘new_fruits.zip’ saved [12125632/12125632]\n","\n","Archive:  new_fruits.zip\n","   creating: new_fruits/apples/\n","  inflating: new_fruits/apples/apples1.jpg  \n","  inflating: new_fruits/apples/apples2.jpg  \n","  inflating: new_fruits/apples/apples3.jpg  \n","  inflating: new_fruits/apples/apples4.jpg  \n","  inflating: new_fruits/apples/apples5.jpg  \n","  inflating: new_fruits/apples/apples6.jpg  \n","  inflating: new_fruits/apples/apples7.jpg  \n","  inflating: new_fruits/apples/apples8.jpg  \n","   creating: new_fruits/oranges/\n","  inflating: new_fruits/oranges/oranges1.jpg  \n","  inflating: new_fruits/oranges/oranges10.jpg  \n","  inflating: new_fruits/oranges/oranges11.jpg  \n","  inflating: new_fruits/oranges/oranges12.jpg  \n","  inflating: new_fruits/oranges/oranges13.jpg  \n","  inflating: new_fruits/oranges/oranges14.jpg  \n","  inflating: new_fruits/oranges/oranges15.jpg  \n","  inflating: new_fruits/oranges/oranges16.jpg  \n","  inflating: new_fruits/oranges/oranges17.jpg  \n","  inflating: new_fruits/oranges/oranges18.jpg  \n","  inflating: new_fruits/oranges/oranges19.jpg  \n","  inflating: new_fruits/oranges/oranges2.jpg  \n","  inflating: new_fruits/oranges/oranges3.jpg  \n","  inflating: new_fruits/oranges/oranges4.jpg  \n","  inflating: new_fruits/oranges/oranges5.jpg  \n","  inflating: new_fruits/oranges/oranges6.jpg  \n","  inflating: new_fruits/oranges/oranges7.jpg  \n","  inflating: new_fruits/oranges/oranges8.jpg  \n","  inflating: new_fruits/oranges/oranges9.jpg  \n","  inflating: new_fruits/oranges/orange-val-copy-1.jpg  \n","  inflating: new_fruits/oranges/Orange-valencia.jpg  \n","  inflating: new_fruits/oranges/valencia-orange_4.jpg  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ce_CKstfGTQV","colab_type":"code","outputId":"e6e1531e-f43d-42cb-85eb-cadb08d55f16","executionInfo":{"status":"ok","timestamp":1565617977304,"user_tz":240,"elapsed":45654,"user":{"displayName":"Etienne Lord","photoUrl":"https://lh4.googleusercontent.com/-5aPJcqV56uo/AAAAAAAAAAI/AAAAAAAABZE/kxLls5iyY-M/s64/photo.jpg","userId":"18414272008349868197"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#!/usr/bin/python\n","#\n","# Fruits part 2. Using transfer learning with MobileNet\n","# Inpired by the code from Francois, Chollet. \n","#                     \"Deep learning with Python.\" Manning (2018) 362 pages.\n","# And \n","# https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/\n","###############################################################################\n","# Global import                                                               #\n","###############################################################################\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","import glob\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from keras.applications import nasnet\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from keras.models import Sequential, Input\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras.optimizers import RMSprop\n","from keras.callbacks import *\n","from keras import backend as K\n","\n","###############################################################################\n","# HELPER FUNCTIONS                                                            #\n","###############################################################################\n","def number_of_files(dirname):\n","    cpt = sum([len(files) for r, d, files in os.walk(dirname)])\n","    return cpt\n","\n","################################################################################ \n","# DEFINITION OF INPUT DATA                                                     #\n","################################################################################\n","test_data_dir='new_fruits'\n","epochs = 50    # Number of iteration over the dataset\n","batch_size = 5 # Number of images processed at the same time\n","nb_test_samples=number_of_files(test_data_dir)\n","img_width, img_height = 224, 224 # Needed dimensions for most model\n","\n","################################################################################ \n","# ResNet, MobileNet or other                                                   #\n","################################################################################\n","#See available models at https://keras.io/applications/#documentation-for-individual-models\n","model_nasnet = nasnet.NASNetMobile(weights=\"imagenet\",input_shape=(img_width, img_height, 3))\n","\n","test_generator = ImageDataGenerator(preprocessing_function = nasnet.preprocess_input).flow_from_directory(\n","    test_data_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","\tshuffle=False,\n","\t)\n","\n","predicted=model_nasnet.predict_generator(test_generator,steps = nb_test_samples // batch_size)\n","\n","y_pred=nasnet.decode_predictions(predicted, top=1)\n","results=pd.DataFrame(np.concatenate(y_pred), columns=['imagenet_id','predict_class','percent']) \n","results[\"filename\"]=test_generator.filenames\n","print(results)\n","results.to_csv(\"predicted.csv\", sep=\",\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0812 13:52:13.232652 139643386144640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0812 13:52:13.272559 139643386144640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0812 13:52:13.280072 139643386144640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","W0812 13:52:13.327768 139643386144640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0812 13:52:13.329330 139643386144640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0812 13:52:13.654407 139643386144640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","W0812 13:52:14.303215 139643386144640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","W0812 13:52:14.502507 139643386144640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile.h5\n","24231936/24227760 [==============================] - 1s 0us/step\n","Found 30 images belonging to 2 classes.\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","40960/35363 [==================================] - 0s 0us/step\n","   imagenet_id predict_class     percent                       filename\n","0    n12620546           hip   0.6390811             apples/apples1.jpg\n","1    n12620546           hip  0.87717247             apples/apples2.jpg\n","2    n12620546           hip   0.1899739             apples/apples3.jpg\n","3    n07754684     jackfruit   0.8219086             apples/apples4.jpg\n","4    n12620546           hip  0.92733884             apples/apples5.jpg\n","5    n07749582         lemon  0.23427123             apples/apples6.jpg\n","6    n12620546           hip  0.79833865             apples/apples7.jpg\n","7    n07749582         lemon   0.7393232             apples/apples8.jpg\n","8    n03991062           pot  0.33480656    oranges/Orange-valencia.jpg\n","9    n07747607        orange  0.55466527  oranges/orange-val-copy-1.jpg\n","10   n09468604        valley  0.32215124           oranges/oranges1.jpg\n","11   n12620546           hip  0.51108426          oranges/oranges10.jpg\n","12   n09468604        valley  0.36917955          oranges/oranges11.jpg\n","13   n07749582         lemon  0.82118434          oranges/oranges12.jpg\n","14   n03930313  picket_fence   0.3706017          oranges/oranges13.jpg\n","15   n11879895      rapeseed   0.8107259          oranges/oranges14.jpg\n","16   n07749582         lemon   0.5512454          oranges/oranges15.jpg\n","17   n07747607        orange   0.6745628          oranges/oranges16.jpg\n","18   n07747607        orange   0.5713706          oranges/oranges17.jpg\n","19   n07747607        orange   0.5099549          oranges/oranges18.jpg\n","20   n03991062           pot  0.90375996          oranges/oranges19.jpg\n","21   n11879895      rapeseed   0.9166423           oranges/oranges2.jpg\n","22   n07749582         lemon   0.8987371           oranges/oranges3.jpg\n","23   n07749582         lemon  0.48490667           oranges/oranges4.jpg\n","24   n07747607        orange   0.8840634           oranges/oranges5.jpg\n","25   n07749582         lemon   0.8987371           oranges/oranges6.jpg\n","26   n12768682       buckeye  0.33010343           oranges/oranges7.jpg\n","27   n07749582         lemon   0.8298147           oranges/oranges8.jpg\n","28   n07747607        orange  0.84375685           oranges/oranges9.jpg\n","29   n07749582         lemon   0.9203106  oranges/valencia-orange_4.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jb0MoWV8J-Eq","colab_type":"code","outputId":"a410b992-73bd-4dea-b88f-24321ba06d2f","executionInfo":{"status":"ok","timestamp":1565618942426,"user_tz":240,"elapsed":1282,"user":{"displayName":"Etienne Lord","photoUrl":"https://lh4.googleusercontent.com/-5aPJcqV56uo/AAAAAAAAAAI/AAAAAAAABZE/kxLls5iyY-M/s64/photo.jpg","userId":"18414272008349868197"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["################################################################################ \n","# UPLOAD THE PREDICTION TO GOOGLE.DRIVE                                        #\n","################################################################################\n","# Display current instance files\n","!ls -alrth\n","# Mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# Copy the predicted.cvs to your google drive\n","!cp predicted.csv /content/drive/'My Drive'/\n","\n","\n","################################################################################\n","# TO DO                                                                        #\n","################################################################################\n","# 1. Train for the apples\n","# 2. Test other models "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cp: target 'Drive/' is not a directory\n"],"name":"stdout"}]}]}